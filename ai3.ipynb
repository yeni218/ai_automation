{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a42aa731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Gemini client initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import pyautogui\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from PIL import Image, ImageGrab\n",
    "from pywinauto.findwindows import find_element\n",
    "\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import ultralytics\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from PIL import Image\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "\n",
    "\n",
    "\n",
    "# --- API Key Handling for Local Environment ---\n",
    "# Get the API key from an environment variable\n",
    "API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if API_KEY:\n",
    "    # Initialize the Gemini client with your API key\n",
    "    client = genai.Client(api_key=API_KEY)\n",
    "    print(\"‚úÖ Gemini client initialized successfully.\")\n",
    "else:\n",
    "    print(\"üõë API Key not found. Please set the GOOGLE_API_KEY environment variable and restart the kernel.\")\n",
    "\n",
    "# A simpler, but less secure alternative (uncomment below if you prefer)\n",
    "# WARNING: Do not share your notebook if you paste your key directly.\n",
    "# API_KEY = \"YOUR_API_KEY_HERE\"\n",
    "# client = genai.Client(api_key=API_KEY)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fc77f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(image: Image.Image, prompt: str, temp: float = 0.2) -> str:\n",
    "    \"\"\"\n",
    "    Performs inference using the client.models.generate_content method,\n",
    "    which is the correct structure for your environment.\n",
    "    \"\"\"\n",
    "    if not client:\n",
    "        raise ValueError(\"Gemini client is not initialized.\")\n",
    "\n",
    "    try:\n",
    "        \n",
    "        generation_config = genai.types.GenerationConfig(\n",
    "            temperature=temp,\n",
    "            # We must rely on prompt engineering for JSON as this old method might not\n",
    "            # support response_mime_type in the config.\n",
    "        )\n",
    "\n",
    "        # THE CORRECT API CALL, based on our debug results and your working example.\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.5-flash\",\n",
    "            contents=[prompt, image],\n",
    "            config=types.GenerateContentConfig(\n",
    "                temperature=temp,\n",
    "            ),\n",
    "        )\n",
    "        \n",
    "        # Clean the response just in case it's wrapped in markdown\n",
    "        cleaned_text = response.text.strip().replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "        return cleaned_text\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during Gemini API call: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79046da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test case\n",
    "def test_inference():\n",
    "    # 1. Load a test image (replace with your image path)\n",
    "    test_image = Image.open(\"masaustu.png\")  # or create a blank image: Image.new('RGB', (100, 100))\n",
    "    \n",
    "    # 2. Define a test prompt\n",
    "    test_prompt = \"Describe this image in detail.\"\n",
    "    \n",
    "    # 3. Call the function\n",
    "    result = inference(image=test_image, prompt=test_prompt, temp=0.2)\n",
    "    \n",
    "    # 4. Print the result\n",
    "    print(\"Gemini Response:\")\n",
    "    print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6d83e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini Response:\n",
      "This image displays a computer desktop, likely running Windows 11, characterized by a clean, dark aesthetic.\n",
      "\n",
      "**Overall Appearance:**\n",
      "The dominant feature is the desktop background, which is a solid, uniform dark gray or charcoal color, providing a minimalist backdrop. There are no patterns, images, or gradients on the wallpaper.\n",
      "\n",
      "**Desktop Icons (Left Side):**\n",
      "A series of application shortcuts, files, and folders are neatly arranged in columns along the left side of the screen. From top to bottom, left to right:\n",
      "\n",
      "*   **Row 1:**\n",
      "    *   A standard \"Recycle Bin\" icon (blue bin with recycling arrows).\n",
      "    *   A red PDF icon labeled \"SD-WEB 2C Kurulum Pr...\" (likely a setup file).\n",
      "    *   A Microsoft Edge browser icon (blue-green swirl) labeled \"logo-icon...\".\n",
      "    *   A purple icon with wavy lines, labeled \"LM Studio\".\n",
      "*   **Row 2:**\n",
      "    *   A yellow icon with a white checkmark, labeled \"Norton 360\".\n",
      "    *   A generic white document icon labeled \"Application...\".\n",
      "    *   A green rectangular icon, likely a screenshot, labeled \"Screenshot 2025-07-0...\".\n",
      "    *   A black icon with a white abstract face, labeled \"copilot_log...\".\n",
      "*   **Row 3:**\n",
      "    *   A blue Microsoft Word document icon with a 'W', labeled \"AKTARIM A≈ûAMALA...\" (Turkish for \"TRANSFER STAGES...\").\n",
      "    *   A yellow folder icon labeled \"Projects\".\n",
      "    *   Another Microsoft Edge icon labeled \"logo-dark...\".\n",
      "    *   A small image preview showing a window with a close 'X' button, labeled \"close_ui.png\".\n",
      "*   **Row 4:**\n",
      "    *   The Google Chrome browser icon (red, yellow, green circle) labeled \"Google Chrome\".\n",
      "    *   A small image preview showing lines of code or text, labeled \"Screenshot 2025-07-0...\".\n",
      "    *   Another Microsoft Edge icon labeled \"auth-logo...\".\n",
      "    *   A small image preview showing a white window, labeled \"cla.png\".\n",
      "*   **Row 5:**\n",
      "    *   The Microsoft Edge browser icon labeled \"Microsoft Edge\".\n",
      "    *   A small image preview showing a blue logo with \"DMN SOFTWARE\" text, labeled \"logo.png\".\n",
      "    *   A blue 'X' icon, labeled \"Alpemix.exe\" (likely a remote access tool).\n",
      "    *   A blue 'X' icon with \"DMN\" text, labeled \"dmn.PNG\".\n",
      "*   **Row 6:**\n",
      "    *   The Visual Studio Code icon (blue and purple abstract shape) labeled \"Visual Studio Code\".\n",
      "    *   A red 'Ae' icon, likely Adobe Express, labeled \"Adobe Express...\".\n",
      "    *   A small image preview showing a browser window, labeled \"Screenshot 2025-07-0...\".\n",
      "    *   Another small image preview showing a different browser window, labeled \"Screenshot 2025-07-1...\".\n",
      "\n",
      "Many of the icons have a small blue square with a white upward-pointing arrow in the bottom-left corner, indicating they are shortcuts.\n",
      "\n",
      "**Taskbar (Bottom):**\n",
      "A translucent, light gray taskbar spans the bottom of the screen.\n",
      "\n",
      "*   **Left Side:**\n",
      "    *   A blue icon with a red '4' notification badge (possibly a communication app like Microsoft Teams).\n",
      "    *   The Windows Start button.\n",
      "    *   A magnifying glass (Search).\n",
      "    *   The Task View icon (two overlapping rectangles).\n",
      "    *   The Widgets icon (blue and white squares).\n",
      "    *   A purple chat bubble icon.\n",
      "    *   A yellow File Explorer folder icon.\n",
      "    *   Pinned application icons, including: Microsoft Edge, Visual Studio Code, Visual Studio, Google Chrome, Outlook, LM Studio, Calculator, Sticky Notes, Calendar, and Paint.\n",
      "*   **Right Side:**\n",
      "    *   An upward-pointing arrow (for hidden icons).\n",
      "    *   \"TUR\" (indicating Turkish language input).\n",
      "    *   A speaker icon (volume control).\n",
      "    *   A Wi-Fi signal icon.\n",
      "    *   A battery icon, showing it is plugged in.\n",
      "    *   The current time and date: \"4:17 PM\" and \"7/11/2025\".\n",
      "\n",
      "The overall impression is a functional and organized desktop environment, with a focus on development tools, productivity applications, and general browsing.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5e653387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run this cell\n",
    "def take_screenshot() -> Image.Image:\n",
    "    \"\"\"Takes a screenshot and returns it as a PIL Image object.\"\"\"\n",
    "    screenshot = ImageGrab.grab()\n",
    "    print(\"üì∏ Screenshot captured.\")\n",
    "    return screenshot\n",
    "\n",
    "def get_center_point(box_coords):\n",
    "    \"\"\"Calculates the center point of a bounding box.\"\"\"\n",
    "    y1, x1, y2, x2 = box_coords\n",
    "    center_x = x1 + (x2 - x1) // 2\n",
    "    center_y = y1 + (y2 - y1) // 2\n",
    "    return  center_y, center_x\n",
    "\n",
    "def perform_action_on_location(location_data_json: str, action: str, **kwargs):\n",
    "    \"\"\"\n",
    "    Parses location data from the AI and performs a specified action on the GUI.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = json.loads(location_data_json)\n",
    "        box = data.get(\"box_2d\")\n",
    "        description = data.get(\"description\", \"Unknown Element\")\n",
    "        if not box or len(box) != 4:\n",
    "            print(f\"Error: Invalid 'box_2d' data in JSON: {location_data_json}\")\n",
    "            return\n",
    "        center_x, center_y = get_center_point(box)\n",
    "        print(f\"ü§ñ Action '{action}' on '{description}' at ({center_x}, {center_y})\")\n",
    "        action = action.lower()\n",
    "        if action == 'hover': pyautogui.moveTo(center_x, center_y, duration=0.25)\n",
    "        elif action == 'click': pyautogui.click(center_x, center_y)\n",
    "        elif action == 'double_click': pyautogui.doubleClick(center_x, center_y)\n",
    "        elif action == 'right_click': pyautogui.rightClick(center_x, center_y)\n",
    "        elif action == 'type':\n",
    "            text = kwargs.get('text_to_type'); pyautogui.click(center_x, center_y); pyautogui.typewrite(text, interval=0.05)\n",
    "        elif action in ['reliable_click', 'reliable_right_click', 'reliable_double_click']:\n",
    "            try:\n",
    "                element = find_element(coords=(center_x, center_y), backend='uia')\n",
    "                if action == 'reliable_click': element.click_input()\n",
    "                elif action == 'reliable_right_click': element.right_click_input()\n",
    "                elif action == 'reliable_double_click': element.double_click_input()\n",
    "            except Exception:\n",
    "                if action == 'reliable_click': pyautogui.click(center_x, center_y)\n",
    "                elif action == 'reliable_right_click': pyautogui.rightClick(center_x, center_y)\n",
    "                elif action == 'reliable_double_click': pyautogui.doubleClick(center_x, center_y)\n",
    "        else: print(f\"Error: Unknown action '{action}'\")\n",
    "    except json.JSONDecodeError: print(f\"Error: Invalid JSON from AI: {location_data_json}\")\n",
    "    except Exception as e: print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1deb70b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with real mouse movements in 3 seconds...\n",
      "Move mouse to corner to abort!\n",
      "ü§ñ Action 'click' on 'test' at (16, 1500)\n",
      "Did the mouse click at (150, 150)?\n"
     ]
    }
   ],
   "source": [
    "def live_action_test():\n",
    "    \"\"\"Test with REAL mouse movements\"\"\"\n",
    "    print(\"Testing with real mouse movements in 3 seconds...\")\n",
    "    print(\"Move mouse to corner to abort!\")\n",
    "    for i in range(3, 0, -1):\n",
    "        print(f\"{i}...\", end=\"\\r\")\n",
    "        time.sleep(1)\n",
    "    \n",
    "    # This will actually move and click\n",
    "    perform_action_on_location(\n",
    "        '{\"box_2d\": [12,1000,20,2000], \"description\": \"test\"}',\n",
    "        \"click\"\n",
    "    )\n",
    "    print(\"Did the mouse click at (150, 150)?\")\n",
    "\n",
    "live_action_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e250566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui\n",
    "\n",
    "# Test basic mouse movement (watch your cursor)\n",
    "pyautogui.moveTo(1000, 100, duration=1)  # Should visibly move\n",
    "pyautogui.click()  # Should click at (100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c406045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì∏ Screenshot captured.\n",
      "Screenshot captured. Size: (1920, 1080) (should match your screen resolution)\n"
     ]
    }
   ],
   "source": [
    "def test_screenshot():\n",
    "    try:\n",
    "        img = take_screenshot()\n",
    "        print(f\"Screenshot captured. Size: {img.size} (should match your screen resolution)\")\n",
    "        # img.show()  # Uncomment to actually see the screenshot\n",
    "    except Exception as e:\n",
    "        print(f\"Screenshot failed: {e}\")\n",
    "\n",
    "test_screenshot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "376b8181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì (0, 0, 100, 100) ‚Üí (50, 50)\n",
      "‚úì (10, 20, 30, 60) ‚Üí (20, 40)\n",
      "‚úì (5, 5, 15, 25) ‚Üí (10, 15)\n"
     ]
    }
   ],
   "source": [
    "def test_center_point():\n",
    "    test_cases = [\n",
    "        ((0, 0, 100, 100), (50, 50)),    # Simple square\n",
    "        ((10, 20, 30, 60), (20, 40)),    # Rectangle\n",
    "        ((5, 5, 15, 25), (10, 15))       # Small rectangle\n",
    "    ]\n",
    "    \n",
    "    for coords, expected in test_cases:\n",
    "        result = get_center_point(coords)\n",
    "        assert result == expected, f\"Failed: {coords} ‚Üí {result} (expected {expected})\"\n",
    "        print(f\"‚úì {coords} ‚Üí {result}\")\n",
    "\n",
    "test_center_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf3ae5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing actions (will not move real mouse):\n",
      "\n",
      "Case: valid_click\n",
      "Input: {\"box_2d\": [100, 100, 200, 200], \"description\": \"Test Button\"}\n",
      "ü§ñ Action 'click' on 'Test Button' at (150, 150)\n",
      "\n",
      "Case: invalid_json\n",
      "Input: not a json\n",
      "Error: Invalid JSON from AI: not a json\n",
      "\n",
      "Case: missing_box\n",
      "Input: {\"description\": \"No coordinates\"}\n",
      "Error: Invalid 'box_2d' data in JSON: {\"description\": \"No coordinates\"}\n",
      "\n",
      "Case: typing_test\n",
      "Input: {\"box_2d\": [50, 50, 150, 150]}\n",
      "ü§ñ Action 'type' on 'Unknown Element' at (100, 100)\n"
     ]
    }
   ],
   "source": [
    "def test_actions():\n",
    "    # Mock JSON data (what we expect from the AI)\n",
    "    test_data = {\n",
    "        \"valid_click\": ('{\"box_2d\": [100, 100, 200, 200], \"description\": \"Test Button\"}', \"click\"),\n",
    "        \"invalid_json\": (\"not a json\", \"hover\"),\n",
    "        \"missing_box\": ('{\"description\": \"No coordinates\"}', \"click\"),\n",
    "        \"typing_test\": ('{\"box_2d\": [50, 50, 150, 150]}', \"type\", {\"text_to_type\": \"Hello\"})\n",
    "    }\n",
    "    \n",
    "    print(\"\\nTesting actions (will not move real mouse):\")\n",
    "    for name, (json_str, action, *args) in test_data.items():\n",
    "        kwargs = args[0] if args else {}\n",
    "        print(f\"\\nCase: {name}\")\n",
    "        print(f\"Input: {json_str}\")\n",
    "        perform_action_on_location(json_str, action, **kwargs)\n",
    "\n",
    "test_actions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9a3ff64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run this cell too\n",
    "def real_ai_vision_model(screen_image: Image.Image, object_to_find: str) -> str | None:\n",
    "    \"\"\"\n",
    "    Sends the screenshot to the Gemini model to find an object and returns its location.\n",
    "    \"\"\"\n",
    "    print(f\"üß† AI Model: Analyzing screen to find '{object_to_find}'...\")\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert AI assistant for GUI automation. Analyze the provided screenshot and locate the UI element described as: \"{object_to_find}\".\n",
    "    Respond with ONLY a JSON object with two keys: \"box_2d\" and \"description\".\n",
    "    Do not include any other text or markdown formatting. If you cannot find it, return JSON with an empty list for \"box_2d\".\n",
    "    \"\"\"\n",
    "    ai_response_text = inference(screen_image, prompt) # This now calls the new function\n",
    "    if not ai_response_text:\n",
    "        print(\"AI Model: Received no response.\"); return None\n",
    "    print(f\"üîç AI Raw Response:\\n{ai_response_text}\")\n",
    "    try:\n",
    "        response_json = json.loads(ai_response_text)\n",
    "        if \"box_2d\" in response_json and response_json[\"box_2d\"]:\n",
    "            return ai_response_text\n",
    "        else:\n",
    "            print(f\"AI Model: Could not find '{object_to_find}'.\"); return None\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"AI Model: Failed to decode JSON from response.\"); return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21a458e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Demo 2: Right-clicking the Start Menu ---\n",
      "üì∏ Screenshot captured.\n",
      "üß† AI Model: Analyzing screen to find 'start menu button'...\n",
      "üîç AI Raw Response:\n",
      "{\"box_2d\": [225, 946, 260, 970], \"description\": \"start menu button\"}\n",
      "ü§ñ Action 'right_click' on 'start menu button' at (958, 242)\n"
     ]
    }
   ],
   "source": [
    "# # --- MAIN EXECUTION EXAMPLE ---\n",
    "# print(\"Starting automation in 5 seconds. Please switch to your target window (e.g., the Desktop).\")\n",
    "# for i in range(5, 0, -1):\n",
    "#     print(f\"{i}...\"); time.sleep(1)\n",
    "# print(\"Go!\")\n",
    "\n",
    "# # --- Demo 1: Double-clicking the Recycle Bin ---\n",
    "# print(\"\\n--- Demo 1: Double-clicking the Recycle Bin ---\")\n",
    "# screen_image = take_screenshot()\n",
    "# recycle_bin_location_json = real_ai_vision_model(screen_image, \"The Recycle Bin icon\")\n",
    "# if recycle_bin_location_json:\n",
    "#     perform_action_on_location(recycle_bin_location_json, \"reliable_double_click\")\n",
    "# else:\n",
    "#     print(\"Could not perform action because the Recycle Bin was not found.\")\n",
    "\n",
    "# time.sleep(5) \n",
    "# print(\"\\nClose any open windows before the next step.\")\n",
    "# time.sleep(3)\n",
    "\n",
    "# --- Demo 2: Right-clicking the Start Menu ---\n",
    "print(\"\\n--- Demo 2: Right-clicking the Start Menu ---\")\n",
    "screen_image_2 = take_screenshot()\n",
    "start_menu_location_json = real_ai_vision_model(screen_image_2, \"start menu button\")\n",
    "if start_menu_location_json:\n",
    "    perform_action_on_location(start_menu_location_json, \"right_click\")\n",
    "else:\n",
    "    print(\"Could not perform action because the Start Menu was not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "60f01a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Demo 2: Right-clicking the Start Menu ---\n",
      "üì∏ Screenshot captured.\n",
      "üß† AI Model: Analyzing screen to find 'visual studio code icon'...\n",
      "üîç AI Raw Response:\n",
      "{\"box_2d\": [1, 773, 85, 856], \"description\": \"Visual Studio Code icon\"}\n",
      "\n",
      "Showing detected Start Menu button (red box)...\n",
      "\n",
      "Right-clicking Start Menu in 5 seconds...\n",
      "5... 4... 3... 2... 1... ü§ñ Action 'right_click' on 'Visual Studio Code icon' at (43, 814)\n",
      "\n",
      "Right-click performed!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# --- Demo 2: Right-clicking the Start Menu ---\n",
    "print(\"\\n--- Demo 2: Right-clicking the Start Menu ---\")\n",
    "\n",
    "# 1. Take screenshot\n",
    "screen_image_2 = take_screenshot()\n",
    "\n",
    "# 2. Find Start Menu button\n",
    "start_menu_location_json = real_ai_vision_model(screen_image_2, \"visual studio code icon\")  # Changed to \"Google Chrome icon\" for testing\n",
    "\n",
    "if start_menu_location_json:\n",
    "    try:\n",
    "        # 3. Visual confirmation - draw box on screenshot\n",
    "        data = json.loads(start_menu_location_json)\n",
    "        box = data[\"box_2d\"]\n",
    "        description = data[\"description\"]\n",
    "        \n",
    "        # Create a copy of the screenshot to draw on\n",
    "        marked_image = screen_image_2.copy()\n",
    "        draw = ImageDraw.Draw(marked_image)\n",
    "        \n",
    "        # Draw red rectangle around detected area\n",
    "        draw.rectangle(box, outline=\"red\", width=3)\n",
    "        \n",
    "        # Add text label\n",
    "        draw.text((box[0], box[1] - 20), description, fill=\"red\")\n",
    "        \n",
    "        # Show the marked image\n",
    "        print(\"\\nShowing detected Start Menu button (red box)...\")\n",
    "        marked_image.show()\n",
    "        \n",
    "        # 4. Countdown before performing action\n",
    "        print(\"\\nRight-clicking Start Menu in 5 seconds...\")\n",
    "        for i in range(5, 0, -1):\n",
    "            print(f\"{i}...\", end=\" \", flush=True)\n",
    "            time.sleep(1)\n",
    "            \n",
    "        # 5. Perform the right-click\n",
    "        perform_action_on_location(start_menu_location_json, \"right_click\")\n",
    "        print(\"\\nRight-click performed!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during visualization: {str(e)}\")\n",
    "else:\n",
    "    print(\"Could not perform action because the Start Menu was not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bd9731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui\n",
    "pyautogui.FAILSAFE = False\n",
    "# Test basic mouse movement (watch your cursor)\n",
    "pyautogui.moveTo(90, 480, duration=1)  # Should visibly move\n",
    "pyautogui.click()  # Should click at (100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62cb03ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Debug Inspection ---\n",
      "The type of our 'client' object is: <class 'google.genai.client.Client'>\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "Methods and attributes available on the 'client' object:\n",
      "- _aio\n",
      "- _api_client\n",
      "- _batches\n",
      "- _caches\n",
      "- _debug_config\n",
      "- _files\n",
      "- _get_api_client\n",
      "- _models\n",
      "- _operations\n",
      "- _tokens\n",
      "- _tunings\n",
      "- aio\n",
      "- auth_tokens\n",
      "- batches\n",
      "- caches\n",
      "- chats\n",
      "- files\n",
      "- models\n",
      "- operations\n",
      "- tunings\n",
      "- vertexai\n",
      "\n",
      "--- Debug Analysis ---\n",
      "‚ùå 'generate_content' IS NOT in the list. This confirms the error.\n",
      "   This means the 'client' object from 'genai.GenerativeModel()' in your environment\n",
      "   is NOT the modern object we expect. It's a different, older 'Client' type.\n",
      "   The fix is to stop using this object-oriented approach and use a simpler function call.\n"
     ]
    }
   ],
   "source": [
    "# --- DEBUGGING CELL ---\n",
    "\n",
    "# We assume 'client' was created in the previous cell like this:\n",
    "# client = genai.GenerativeModel('gemini-1.5-flash-latest')\n",
    "\n",
    "print(\"--- Starting Debug Inspection ---\")\n",
    "try:\n",
    "    # 1. What is the actual type of our 'client' object?\n",
    "    print(f\"The type of our 'client' object is: {type(client)}\")\n",
    "    print(\"\\n-----------------------------------\\n\")\n",
    "    \n",
    "    # 2. What methods and attributes are available on this object?\n",
    "    print(\"Methods and attributes available on the 'client' object:\")\n",
    "    # The dir() function is a built-in Python tool to list all properties of an object.\n",
    "    # We will print them in an easy-to-read list.\n",
    "    available_attributes = dir(client)\n",
    "    for attr in available_attributes:\n",
    "        # We'll ignore the \"dunder\" (double underscore) methods for clarity\n",
    "        if not attr.startswith('__'):\n",
    "            print(f\"- {attr}\")\n",
    "            \n",
    "    print(\"\\n--- Debug Analysis ---\")\n",
    "    if 'generate_content' in available_attributes:\n",
    "        print(\"‚úÖ 'generate_content' IS in the list. The error is very strange.\")\n",
    "    else:\n",
    "        print(\"‚ùå 'generate_content' IS NOT in the list. This confirms the error.\")\n",
    "        print(\"   This means the 'client' object from 'genai.GenerativeModel()' in your environment\")\n",
    "        print(\"   is NOT the modern object we expect. It's a different, older 'Client' type.\")\n",
    "        print(\"   The fix is to stop using this object-oriented approach and use a simpler function call.\")\n",
    "        \n",
    "except NameError:\n",
    "    print(\"Error: The 'client' object has not been created yet. Please run the initialization cell first.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during debugging: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6dcc2b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size(width=1920, height=1080)\n"
     ]
    }
   ],
   "source": [
    "import pyautogui\n",
    "print(pyautogui.size())  # Should match your actual screen resolution (e.g., 1920x1080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "25a230fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyautogui.moveTo(1800, 100)  # Should visibly move the mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0987458",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
